{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "vocab_size = 2000\n",
    "embedding_size = 32"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "valid_df = pd.read_csv('valid.csv')\n",
    "with open('train.txt', 'w', encoding='utf8') as f:\n",
    "    f.write('\\n'.join(train_df['text']))\n",
    "\n",
    "spm.SentencePieceTrainer.Train('--input=train.txt --model_prefix=train --vocab_size={0} --model_type=unigram --max_sentence_length=9999'.format(vocab_size))\n",
    "vocab_list = pd.read_csv('train.vocab', sep='\\t', header=None, quoting=csv.QUOTE_NONE)\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('train.model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define x_train, y_train tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_train = [0 for _ in range(len(train_df))]\n",
    "for i in range(len(train_df)):\n",
    "    data_train[i] = torch.FloatTensor(sp.encode_as_ids(train_df['text'][i]))\n",
    "\n",
    "data_valid = [0 for _ in range(len(valid_df))]\n",
    "for i in range (len(valid_df)):\n",
    "    data_valid[i] = torch.FloatTensor(sp.encode_as_ids(valid_df['text'][i]))\n",
    "\n",
    "x_train = torch.transpose(pad_sequence(data_train), 0, 1)\n",
    "y_train = torch.FloatTensor(train_df['target'])\n",
    "\n",
    "data_valid.append(torch.zeros(size=[x_train.shape[1]]))\n",
    "x_valid = torch.transpose(pad_sequence(data_valid), 0, 1)[0:-1]\n",
    "y_valid = torch.FloatTensor(valid_df['target'])\n",
    "\n",
    "x_train_maxlen = x_train.shape[-1]\n",
    "\n",
    "\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x_data = x\n",
    "        self.y_data = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = torch.FloatTensor(self.y_data[idx])\n",
    "\n",
    "        return x, y\n",
    "\n",
    "train_set = CustomDataset(x_train, y_train)\n",
    "valid_set = CustomDataset(x_valid, y_valid)\n",
    "\n",
    "trainloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "validloader = DataLoader(valid_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Positional Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, max_len, vocab_size, embedding_dim):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        self.token_emb = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.pos_emb = nn.Embedding(max_len, embedding_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        max_len = x.shape[-1]\n",
    "        positions = torch.arange(start=0, end=max_len, step=1)\n",
    "        positions = self.pos_emb(positions.long())\n",
    "        x = self.token_emb(x.long())\n",
    "        return x + positions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Multi Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads=8):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        assert embedding_dim % self.num_heads == 0\n",
    "\n",
    "        self.projection_dim = embedding_dim // num_heads\n",
    "        self.Wq = nn.Linear(embedding_dim, embedding_dim) \n",
    "        self.Wk = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.Wv = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.Wo = nn.Linear(embedding_dim, embedding_dim)\n",
    "\n",
    "    def self_attention(self, query, key, value):\n",
    "        # query, key, value = (batch size, num heads, seq len, projection dim)\n",
    "        matmul_qk = torch.matmul(query, torch.transpose(key, -1, -2))\n",
    "        # matmul_qk = (batch size, num heads, seq len, seq len)\n",
    "        projection_dim = torch.FloatTensor([key.shape[-1]])\n",
    "        scores = matmul_qk / torch.sqrt(projection_dim)\n",
    "        attention_weights = torch.softmax(scores, axis=-1)\n",
    "        # attention_weights = (batch size, num heads, seq len, seq len)\n",
    "        output = torch.matmul(attention_weights, value)\n",
    "        # output = (batch size, num heads, seq len, projection dim) * 8-head weighted sum of values\n",
    "        return output, attention_weights\n",
    "    \n",
    "    def split_heads(self, x, batch_size):\n",
    "        # x = (batch size, seq len, embedding dim)\n",
    "        # output = (batch size, num heads, seq len, embedding dim / num heads)\n",
    "        x = torch.reshape(x, [batch_size, self.num_heads, -1, self.projection_dim])\n",
    "        return x\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # input shape = (batch size, seq len, embedding dim)\n",
    "        batch_size = inputs.shape[0]\n",
    "\n",
    "        # define query, key, value\n",
    "        query = self.Wq(inputs)\n",
    "        key = self.Wk(inputs)\n",
    "        value = self.Wv(inputs)\n",
    "\n",
    "        # multi-head split q, k, v\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "        \n",
    "        # input, output = (batch size, num heads, seq len, projection dim)\n",
    "        scaled_attention, _ = self.self_attention(query, key, value)\n",
    "\n",
    "        # reshape to concat -> (batch size, seq len, num heads, projection dim)\n",
    "        scaled_attention = torch.transpose(scaled_attention, 1, 2)\n",
    "\n",
    "        # concat -> (batch size, seq len, num heads * projection dim = embedding dim)\n",
    "        concat_attention = torch.reshape(scaled_attention, shape=[batch_size, -1, self.embedding_dim])\n",
    "\n",
    "        # linear embedding dim -> embedding dim\n",
    "        outputs = self.Wo(concat_attention)\n",
    "        return outputs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = x_train_maxlen\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads, dff, dropout=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.multi_head_attention = MultiHeadAttention(embedding_dim, num_heads)\n",
    "        self.ffn = nn.Sequential(nn.Linear(embedding_dim, dff), nn.ReLU(), nn.Linear(dff, embedding_dim))\n",
    "        self.layernorm1 = nn.LayerNorm(normalized_shape=[seq_len, embedding_dim], eps=1e-6)\n",
    "        self.layernorm2 = nn.LayerNorm(normalized_shape=[seq_len, embedding_dim], eps=1e-6)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        a1 = self.dropout1(self.multi_head_attention(x))\n",
    "        a1 = self.layernorm1(x + a1)\n",
    "        a2 = self.dropout2(self.ffn(a1))\n",
    "        a2 = self.layernorm2(a1 + a2)\n",
    "        return a2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Total Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 4\n",
    "dff = 16\n",
    "dropout = 0.1\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.embedding = PositionalEmbedding(x_train_maxlen, vocab_size, embedding_size)\n",
    "        self.transformer_block = TransformerBlock(embedding_size, num_heads, dff, dropout)\n",
    "        self.avg_global_pool = nn.AvgPool1d(kernel_size=seq_len)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.dense = nn.Sequential(nn.Linear(embedding_size, 20), nn.ReLU(), nn.Dropout(0.1), nn.Linear(20, 2), nn.Softmax(dim=1))\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        positional_embedding = self.embedding(x)\n",
    "        transformer_output = self.transformer_block(positional_embedding)\n",
    "        transformer_output = torch.transpose(transformer_output, 1, 2)\n",
    "        transformer_output_2d = torch.squeeze(self.avg_global_pool(transformer_output))\n",
    "    \n",
    "        dense_output = self.dense(self.dropout(transformer_output_2d))\n",
    "        dense_output = torch.transpose(dense_output, 0, 1)\n",
    "        final_scores = dense_output[0]\n",
    "\n",
    "        return final_scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, optimizer, trainloader, validloader, num_epoch, model_path):\n",
    "    for epoch in range(num_epoch):\n",
    "        total_loss = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            optimizer.zero_grad()\n",
    "            x, y = data\n",
    "            result = net(x)\n",
    "            loss = F.binary_cross_entropy(result, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        total_loss = total_loss / len(trainloader)\n",
    "        valid_loss, valid_acc = valid(net, validloader)\n",
    "        print(\"epoch: %d train loss: %.3f valid loss: %.3f valid acc: %.3f\" % (epoch+1, total_loss, valid_loss, valid_acc))\n",
    "\n",
    "def valid(net, dataloader):\n",
    "    net.eval()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        x, y = data\n",
    "        result = net(x)\n",
    "        loss = F.binary_cross_entropy(result, y)\n",
    "        acc = torch.sum(torch.where(abs(result-y)<0.5, 1, 0))\n",
    "        total_loss += loss.item()\n",
    "        total_acc += acc.item()\n",
    "    \n",
    "    total_loss = total_loss / len(dataloader)\n",
    "    total_acc = total_acc / (len(dataloader) * batch_size)\n",
    "\n",
    "    net.train()\n",
    "    return total_loss, total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train loss: 0.671 valid loss: 0.680 valid acc: 0.561\n",
      "epoch: 2 train loss: 0.656 valid loss: 0.676 valid acc: 0.575\n",
      "epoch: 3 train loss: 0.628 valid loss: 0.635 valid acc: 0.626\n",
      "epoch: 4 train loss: 0.592 valid loss: 0.609 valid acc: 0.685\n",
      "epoch: 5 train loss: 0.552 valid loss: 0.579 valid acc: 0.717\n",
      "epoch: 6 train loss: 0.516 valid loss: 0.564 valid acc: 0.710\n",
      "epoch: 7 train loss: 0.483 valid loss: 0.560 valid acc: 0.718\n",
      "epoch: 8 train loss: 0.460 valid loss: 0.569 valid acc: 0.699\n",
      "epoch: 9 train loss: 0.437 valid loss: 0.561 valid acc: 0.717\n",
      "epoch: 10 train loss: 0.422 valid loss: 0.575 valid acc: 0.715\n",
      "epoch: 11 train loss: 0.405 valid loss: 0.590 valid acc: 0.707\n",
      "epoch: 12 train loss: 0.402 valid loss: 0.557 valid acc: 0.719\n",
      "epoch: 13 train loss: 0.384 valid loss: 0.565 valid acc: 0.718\n",
      "epoch: 14 train loss: 0.375 valid loss: 0.605 valid acc: 0.713\n",
      "epoch: 15 train loss: 0.374 valid loss: 0.607 valid acc: 0.704\n",
      "epoch: 16 train loss: 0.357 valid loss: 0.570 valid acc: 0.726\n",
      "epoch: 17 train loss: 0.354 valid loss: 0.560 valid acc: 0.729\n",
      "epoch: 18 train loss: 0.340 valid loss: 0.596 valid acc: 0.722\n",
      "epoch: 19 train loss: 0.330 valid loss: 0.598 valid acc: 0.719\n",
      "epoch: 20 train loss: 0.331 valid loss: 0.602 valid acc: 0.710\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "betas = (0.9, 0.999)\n",
    "net = Net()\n",
    "\n",
    "optimizer = torch.optim.Adam(params=net.parameters(), weight_decay=0.001, lr=lr, betas=betas, eps=1e-8)\n",
    "train(net, optimizer, trainloader, validloader, 20, None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
